# -*- coding: utf-8 -*-
"""
MessageClassifier4 ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
ê¸°ì¡´ ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ê°„ì†Œí™”ëœ MessageClassifier4ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import sys
import os
from statistics import mean
from typing import Dict, List

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.getcwd())

from app.message_classifier2 import MessageClassifier2
from scenario1_discussion_cases import get_scenario1_discussion_cases
from scenario2_discussion_cases import get_scenario2_discussion_cases
from scenario3_discussion_cases import get_scenario3_discussion_cases
from scenario4_discussion_cases import get_scenario4_discussion_cases
from scenario5_discussion_cases import get_scenario5_discussion_cases


class Classifier2ScenarioTester:
    """MessageClassifier2ë¡œ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, similarity_threshold=0.1):
        self.classifier = MessageClassifier2(similarity_threshold)
        
        # ëª¨ë¸ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        self._check_model_status()
        
        self.results = {
            "total_tests": 0,
            "correct_predictions": 0,
            "scenarios": {},
            "method_stats": {
                "explicit_trait": 0,
                "keyword_matching": 0,
                "sum_similarity": 0,
                "classification_failed": 0,
                "skip": 0,
                "analysis_failed": 0,
                "error": 0
            }
        }
    
    def _check_model_status(self):
        """ëª¨ë¸ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸ ë° ì¶œë ¥"""
        print("ğŸ” MessageClassifier2 ëª¨ë¸ ìƒíƒœ í™•ì¸")
        print("=" * 50)
        
        # KoNLPy í˜•íƒœì†Œ ë¶„ì„ê¸° ìƒíƒœ
        morphs_status = "âœ… í™œì„±í™”" if self.classifier.morphs_enabled else "âŒ ë¹„í™œì„±í™”"
        print(f"KoNLPy í˜•íƒœì†Œ ë¶„ì„ê¸°: {morphs_status}")
        
        if self.classifier.morphs_enabled:
            try:
                # ê°„ë‹¨í•œ í˜•íƒœì†Œ ë¶„ì„ í…ŒìŠ¤íŠ¸
                test_result = self.classifier.okt.pos("í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤")
                print(f"  â†’ í˜•íƒœì†Œ ë¶„ì„ í…ŒìŠ¤íŠ¸: âœ… ì •ìƒ ({len(test_result)}ê°œ í˜•íƒœì†Œ ì¶”ì¶œ)")
            except Exception as e:
                print(f"  â†’ í˜•íƒœì†Œ ë¶„ì„ í…ŒìŠ¤íŠ¸: âŒ ì‹¤íŒ¨ - {e}")
        
        # Word2Vec ëª¨ë¸ ìƒíƒœ
        w2v_status = "âœ… ë¡œë“œë¨" if self.classifier.word2vec_model else "âŒ ë¡œë“œ ì‹¤íŒ¨"
        print(f"Word2Vec ëª¨ë¸: {w2v_status}")
        
        if self.classifier.word2vec_model:
            try:
                # ëª¨ë¸ ê¸°ë³¸ ì •ë³´
                if hasattr(self.classifier.word2vec_model, 'key_to_index'):
                    vocab_size = len(self.classifier.word2vec_model.key_to_index)
                    print(f"  â†’ ì–´íœ˜ í¬ê¸°: {vocab_size:,}ê°œ")
                    
                    # í…ŒìŠ¤íŠ¸ ë‹¨ì–´ë¡œ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸
                    test_words = ["ì •ì§", "ì—´ì •", "ì°½ì˜", "ì¡´ì¤‘"]
                    available_words = [w for w in test_words if w in self.classifier.word2vec_model]
                    print(f"  â†’ CJ í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨: {len(available_words)}/4ê°œ ({', '.join(available_words)})")
                    
                    if len(available_words) >= 2:
                        try:
                            sim = self.classifier.word2vec_model.similarity(available_words[0], available_words[1])
                            print(f"  â†’ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸: âœ… {available_words[0]}-{available_words[1]} = {sim:.3f}")
                        except Exception as e:
                            print(f"  â†’ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸: âŒ ì‹¤íŒ¨ - {e}")
                else:
                    print("  â†’ ëª¨ë¸ ì–´íœ˜ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            except Exception as e:
                print(f"  â†’ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        else:
            print("  â†’ Word2Vec ëª¨ë¸ì´ ì—†ì–´ ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ê°€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            print("  â†’ í‚¤ì›Œë“œ ë§¤ì¹­ê³¼ ëª…ì‹œì  íŠ¹ì„± ê²€ì¶œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤")
        
        # ë¶„ë¥˜ê¸° ì„¤ì • ì •ë³´
        print(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {self.classifier.similarity_threshold}")
        print(f"CJ í‚¤ì›Œë“œ ì„¸íŠ¸: 4ê°œ íŠ¹ì„± Ã— {sum(len(keywords) for keywords in self.classifier.cj_keywords.values())}ê°œ í‚¤ì›Œë“œ")
        
        # ê°„ë‹¨í•œ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª ê°„ë‹¨í•œ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸:")
        test_cases = [
            ("ì •ì§í•˜ê²Œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤", "ì •ì§"),
            ("ì—´ì‹¬íˆ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤", "ì—´ì •"),
            ("ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤", "ì°½ì˜"),
            ("ê³ ê°ì„ ë°°ë ¤í•´ì•¼ í•©ë‹ˆë‹¤", "ì¡´ì¤‘")
        ]
        
        for text, expected in test_cases:
            try:
                result = self.classifier.classify(text, "test")
                predicted = result["primary_trait"]
                method = result.get("method", "unknown")
                status = "âœ…" if predicted == expected else "âŒ"
                print(f"  {status} '{text}' â†’ {predicted} ({method})")
            except Exception as e:
                print(f"  âŒ '{text}' â†’ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        
        print("=" * 50)
        print()
    
    def test_scenario(self, scenario_name: str, test_cases: list, show_details: bool = False, 
                      show_test_sentences: bool = False) -> dict:
        """íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print(f"\n{'='*20} {scenario_name} í…ŒìŠ¤íŠ¸ {'='*20}")
        
        scenario_results = {
            "total": len(test_cases),
            "correct": 0,
            "trait_stats": {},
            "method_stats": {"explicit_trait": 0, "keyword_matching": 0, "sum_similarity": 0, 
                           "classification_failed": 0, "skip": 0, "analysis_failed": 0, "error": 0},
            "errors": []
        }
        
        # ì¸ì¬ìƒë³„ í†µê³„ ì´ˆê¸°í™”
        for case in test_cases:
            trait = case["expected_primary"]
            if trait not in scenario_results["trait_stats"]:
                scenario_results["trait_stats"][trait] = {"total": 0, "correct": 0}
        
        print(f"ì´ {len(test_cases)}ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤")
        if show_test_sentences:
            print("-" * 80)
        
        for i, case in enumerate(test_cases):
            text = case["text"]
            expected = case["expected_primary"]
            
            try:
                # MessageClassifier2ë¡œ ë¶„ë¥˜
                result = self.classifier.classify(text, f"{scenario_name}_{i}")
                predicted = result["primary_trait"]
                method = result.get("method", "unknown")
                confidence = result.get("confidence", 0.0)
            except Exception as e:
                print(f"âŒ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¼€ì´ìŠ¤ {i+1}): {e}")
                print(f"   ë¬¸ì¥: {text}")
                result = {
                    "primary_trait": "ë¶„ë¥˜ì˜¤ë¥˜",
                    "method": "error",
                    "confidence": 0.0,
                    "cj_values": {"ì •ì§": 0, "ì—´ì •": 0, "ì°½ì˜": 0, "ì¡´ì¤‘": 0}
                }
                predicted = "ë¶„ë¥˜ì˜¤ë¥˜"
                method = "error"
                confidence = 0.0
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            scenario_results["trait_stats"][expected]["total"] += 1
            if method in scenario_results["method_stats"]:
                scenario_results["method_stats"][method] += 1
            if method in self.results["method_stats"]:
                self.results["method_stats"][method] += 1
            
            if predicted == expected:
                scenario_results["correct"] += 1
                scenario_results["trait_stats"][expected]["correct"] += 1
                status = "âœ…"
            else:
                status = "âŒ"
                scenario_results["errors"].append({
                    "text": text,
                    "expected": expected,
                    "predicted": predicted,
                    "method": method,
                    "confidence": confidence,
                    "scores": result["cj_values"]
                })
            
            # ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ì¶œë ¥
            if show_test_sentences:
                try:
                    print(f"{i+1:3d}. {text}")
                    print(f"     ì˜ˆìƒ: {expected} â†’ ê²°ê³¼: {predicted} {status}")
                    print(f"     ë°©ë²•: {method}, ì‹ ë¢°ë„: {confidence:.3f}")
                    
                    # ë¶„ë¥˜ ì‹¤íŒ¨ë‚˜ ì˜¤ë‹µì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
                    if predicted != expected or method == "classification_failed":
                        print(f"     ì ìˆ˜: {result['cj_values']}")
                        
                        # ë¶„ë¥˜ ì‹¤íŒ¨ íŠ¹ë³„ í‘œì‹œ
                        if method == "classification_failed":
                            print(f"     âš ï¸  ë¶„ë¥˜ ì‹¤íŒ¨: ëª¨ë“  ë¶„ë¥˜ ë°©ë²•ì´ ì„ê³„ê°’ ë¯¸ë‹¬")
                            if result.get('summary'):
                                print(f"     ì‹¤íŒ¨ ì›ì¸: {result['summary']}")
                    
                    if result.get('morphemes'):
                        print(f"     í˜•íƒœì†Œ: {result['morphemes']}")
                    print()
                except Exception as e:
                    print(f"     âŒ ì¶œë ¥ ì˜¤ë¥˜: {e}")
                    print(f"     ê²°ê³¼ ë°ì´í„°: {result}")
                    print()
            
            # ìƒì„¸ ì¶œë ¥ (ì²˜ìŒ 5ê°œë§Œ)
            elif show_details and i < 5:
                print(f"{i+1:2d}. {text[:50]}...")
                print(f"    ì˜ˆìƒ: {expected}, ê²°ê³¼: {predicted} {status}")
                print(f"    ë°©ë²•: {method}, ì‹ ë¢°ë„: {confidence:.3f}")
                print(f"    ì ìˆ˜: {result['cj_values']}")
                if result.get('morphemes'):
                    print(f"    í˜•íƒœì†Œ: {result['morphemes'][:5]}...")
                print()
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ ì¶œë ¥
        accuracy = scenario_results["correct"] / scenario_results["total"] * 100
        print(f"\n{scenario_name} ì •í™•ë„: {scenario_results['correct']}/{scenario_results['total']} = {accuracy:.1f}%")
        
        # ë°©ë²•ë³„ í†µê³„
        print(f"ë¶„ë¥˜ ë°©ë²•ë³„ í†µê³„:")
        for method, count in scenario_results["method_stats"].items():
            if count > 0:
                percentage = count / scenario_results["total"] * 100
                status_icon = "âš ï¸ " if method == "classification_failed" else ""
                print(f"  {status_icon}{method}: {count}ê°œ ({percentage:.1f}%)")
        
        # ì¸ì¬ìƒë³„ ì •í™•ë„
        print(f"ì¸ì¬ìƒë³„ ì •í™•ë„:")
        for trait, stats in scenario_results["trait_stats"].items():
            trait_accuracy = stats["correct"] / stats["total"] * 100 if stats["total"] > 0 else 0
            print(f"  {trait}: {stats['correct']}/{stats['total']} = {trait_accuracy:.1f}%")
        
        return scenario_results
    
    def show_error_analysis(self, scenario_name: str, errors: list, max_errors: int = None):
        """ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„ - ëª¨ë“  ì˜¤ë‹µ í‘œì‹œ"""
        if not errors:
            print(f"\n{scenario_name}: ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ê°€ ì •í™•íˆ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
            return
        
        # max_errorsê°€ Noneì´ë©´ ëª¨ë“  ì˜¤ë‹µì„ í‘œì‹œ
        if max_errors is None:
            max_errors = len(errors)
            print(f"\n{scenario_name} ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„ (ì´ {len(errors)}ê°œ ì „ì²´):")
        else:
            print(f"\n{scenario_name} ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„ (ì´ {len(errors)}ê°œ ì¤‘ {min(max_errors, len(errors))}ê°œ):")
        
        print("-" * 80)
        
        for i, error in enumerate(errors[:max_errors]):
            print(f"{i+1}. ë¬¸ì¥: '{error['text']}'")
            print(f"   ì˜ˆìƒ: {error['expected']} vs ì˜ˆì¸¡: {error['predicted']}")
            print(f"   ë°©ë²•: {error['method']}, ì‹ ë¢°ë„: {error['confidence']:.3f}")
            print(f"   ì ìˆ˜: {error['scores']}")
            
            # ë¶„ë¥˜ ì‹¤íŒ¨ íŠ¹ë³„ í‘œì‹œ
            if error['method'] == 'classification_failed':
                print(f"   âš ï¸  ë¶„ë¥˜ ì‹¤íŒ¨: ëª¨ë“  ë¶„ë¥˜ ë°©ë²•ì´ ì„ê³„ê°’ ë¯¸ë‹¬")
            else:
                # ì ìˆ˜ ì°¨ì´ ë¶„ì„ (ë¶„ë¥˜ ì‹¤íŒ¨ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
                expected_score = error['scores'][error['expected']]
                predicted_score = error['scores'][error['predicted']]
                score_diff = predicted_score - expected_score
                print(f"   ì ìˆ˜ ì°¨ì´: {error['predicted']}({predicted_score}) - {error['expected']}({expected_score}) = {score_diff:+d}")
            print()
    
    def run_all_tests(self, show_details: bool = False, show_test_sentences: bool = False):
        """ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª MessageClassifier2 - ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì¢…í•© í…ŒìŠ¤íŠ¸")
        print("=" * 80)
        print("ê°„ì†Œí™”ëœ Sum ë°©ì‹ ë¶„ë¥˜ê¸°ë¡œ 5ê°œ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì‹¤ì œ í† ë¡  ë°œì–¸ ë¶„ë¥˜ ì„±ëŠ¥ ê²€ì¦")
        if show_test_sentences:
            print("ğŸ“ ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ê³¼ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.")
        print()
        
        # ê° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
        scenarios = [
            ("ì‹œë‚˜ë¦¬ì˜¤ 1: ê°“ êµ¬ìš´ ë¹µì˜ ë¹„ë°€", get_scenario1_discussion_cases()),
            ("ì‹œë‚˜ë¦¬ì˜¤ 2: ì•Œë°”ìƒ í˜œê²½ì´ì˜ ì—´ì •", get_scenario2_discussion_cases()),
            ("ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹ ë©”ë‰´ ê°œë°œ ì•„ì´ë””ì–´", get_scenario3_discussion_cases()),
            ("ì‹œë‚˜ë¦¬ì˜¤ 4: ê³ ê° ë¶ˆë§Œ ì‘ëŒ€", get_scenario4_discussion_cases()),
            ("ì‹œë‚˜ë¦¬ì˜¤ 5: ë¹•ìŠ¤ ì¡°ë¦¬ ê·¼ë¬´ì", get_scenario5_discussion_cases())
        ]
        
        total_correct = 0
        total_tests = 0
        
        for scenario_name, test_cases in scenarios:
            scenario_results = self.test_scenario(scenario_name, test_cases, show_details, show_test_sentences)
            
            self.results["scenarios"][scenario_name] = scenario_results
            total_correct += scenario_results["correct"]
            total_tests += scenario_results["total"]
        
        # ì „ì²´ ê²°ê³¼ ìš”ì•½
        overall_accuracy = total_correct / total_tests * 100
        print("\n" + "="*80)
        print("ğŸ“Š MessageClassifier2 ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        print(f"ì „ì²´ ì •í™•ë„: {total_correct}/{total_tests} = {overall_accuracy:.1f}%")
        print()
        
        # ì „ì²´ ë°©ë²•ë³„ í†µê³„
        print("ì „ì²´ ë¶„ë¥˜ ë°©ë²•ë³„ í†µê³„:")
        for method, count in self.results["method_stats"].items():
            if count > 0:
                percentage = count / total_tests * 100
                status_icon = "âš ï¸ " if method == "classification_failed" else ""
                print(f"  {status_icon}{method}: {count}ê°œ ({percentage:.1f}%)")
        print()
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìš”ì•½
        print("ì‹œë‚˜ë¦¬ì˜¤ë³„ ì •í™•ë„:")
        for scenario_name, results in self.results["scenarios"].items():
            accuracy = results["correct"] / results["total"] * 100
            print(f"  {scenario_name}: {accuracy:.1f}% ({results['correct']}/{results['total']})")
        
        print()
        
        # ì „ì²´ ì¸ì¬ìƒë³„ í†µê³„
        self.show_overall_trait_stats()
        
        # ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜¤ë¶„ë¥˜ ë¶„ì„
        print("\n" + "="*80)
        print("ğŸ” ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„")
        print("="*80)
        
        for scenario_name, results in self.results["scenarios"].items():
            self.show_error_analysis(scenario_name, results["errors"], max_errors=None)  # ëª¨ë“  ì˜¤ë‹µ í‘œì‹œ
        
        # ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„
        self.show_performance_analysis(overall_accuracy, total_tests)
        
        # ì˜¤ë‹µ ë¬¸ì¥ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
        self.save_incorrect_sentences()
    
    def show_overall_trait_stats(self):
        """ì „ì²´ ì¸ì¬ìƒë³„ í†µê³„"""
        overall_trait_stats = {}
        
        # ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì˜ ì¸ì¬ìƒë³„ í†µê³„ ì§‘ê³„
        for scenario_results in self.results["scenarios"].values():
            for trait, stats in scenario_results["trait_stats"].items():
                if trait not in overall_trait_stats:
                    overall_trait_stats[trait] = {"total": 0, "correct": 0}
                overall_trait_stats[trait]["total"] += stats["total"]
                overall_trait_stats[trait]["correct"] += stats["correct"]
        
        print("ì „ì²´ ì¸ì¬ìƒë³„ ì •í™•ë„:")
        for trait, stats in overall_trait_stats.items():
            if stats["total"] > 0:
                accuracy = stats["correct"] / stats["total"] * 100
                print(f"  {trait}: {stats['correct']}/{stats['total']} = {accuracy:.1f}%")
    
    def show_performance_analysis(self, accuracy, total_tests):
        """ì„±ëŠ¥ ë¶„ì„ ë° ê°œì„  ì œì•ˆ"""
        print("\n" + "="*80)
        print("ğŸ” MessageClassifier2 ì„±ëŠ¥ ë¶„ì„")
        print("="*80)
        
        explicit_success = self.results["method_stats"]["explicit_trait"]
        keyword_success = self.results["method_stats"]["keyword_matching"]
        similarity_success = self.results["method_stats"]["sum_similarity"] 
        failed_classifications = self.results["method_stats"]["classification_failed"]
        
        explicit_rate = explicit_success / total_tests * 100
        keyword_rate = keyword_success / total_tests * 100
        similarity_rate = similarity_success / total_tests * 100
        failure_rate = failed_classifications / total_tests * 100
        
        print(f"ğŸ“ˆ ë¶„ë¥˜ ì„±ê³µë¥  ë¶„ì„:")
        print(f"  - ëª…ì‹œì  ì¸ì¬ìƒ í‚¤ì›Œë“œ: {explicit_rate:.1f}% ({explicit_success}ê°œ)")
        print(f"  - í‚¤ì›Œë“œ ë§¤ì¹­ ì„±ê³µë¥ : {keyword_rate:.1f}% ({keyword_success}ê°œ)")
        print(f"  - Sum ìœ ì‚¬ë„ ì„±ê³µë¥ : {similarity_rate:.1f}% ({similarity_success}ê°œ)")
        print(f"  - âš ï¸  ë¶„ë¥˜ ì‹¤íŒ¨ìœ¨: {failure_rate:.1f}% ({failed_classifications}ê°œ)")
        
        print(f"\nğŸ’¡ ì„±ëŠ¥ ê°œì„  ì œì•ˆ:")
        if failure_rate > 15:
            print(f"  - âš ï¸  ë¶„ë¥˜ ì‹¤íŒ¨ìœ¨ì´ {failure_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤!")
            print(f"    â†’ ìœ ì‚¬ë„ ì„ê³„ê°’({self.classifier.similarity_threshold}) ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")
            print(f"    â†’ Word2Vec ëª¨ë¸ ë¡œë“œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        if failure_rate > 0:
            print(f"  - ë¶„ë¥˜ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ {failed_classifications}ê°œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if similarity_rate < 10:
            print("  - Sum ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜ê°€ ì ìŠµë‹ˆë‹¤. Word2Vec ëª¨ë¸ ê²½ë¡œì™€ í’ˆì§ˆì„ í™•ì¸í•˜ì„¸ìš”.")
        if keyword_rate > 80:
            print("  - í‚¤ì›Œë“œ ë§¤ì¹­ ì˜ì¡´ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ í‘œí˜„ì„ ìœ„í•œ í‚¤ì›Œë“œ í™•ì¥ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        if explicit_rate > 30:
            print("  - ëª…ì‹œì  í‚¤ì›Œë“œ ì˜ì¡´ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ì‹¤ì œ ìƒí™©ì—ì„œëŠ” ëª…ì‹œì  í‘œí˜„ì´ ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        print(f"\nâœ¨ ì „ì²´ ì„±ëŠ¥: {accuracy:.1f}%")
        if accuracy >= 85:
            print("  ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤!")
        elif accuracy >= 75:
            print("  ğŸ‘ ì–‘í˜¸í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤.")
        elif accuracy >= 65:
            print("  âš ï¸  ë³´í†µ ì„±ëŠ¥ì…ë‹ˆë‹¤. ê°œì„ ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        else:
            print("  ğŸ”§ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    def save_incorrect_sentences(self):
        """ì˜¤ë‹µ ë¬¸ì¥ë“¤ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
        from datetime import datetime
        
        # í˜„ì¬ ì‹œê°ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"incorrect_sentences_{timestamp}.txt"
        
        # ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì˜ ì˜¤ë‹µ ë¬¸ì¥ë“¤ ìˆ˜ì§‘
        all_errors = []
        total_errors = 0
        
        print("ğŸ“‹ ì˜¤ë‹µ ìˆ˜ì§‘ ìƒí™©:")
        for scenario_name, results in self.results["scenarios"].items():
            scenario_errors = results["errors"]
            print(f"  - {scenario_name}: {len(scenario_errors)}ê°œ ì˜¤ë‹µ")
            total_errors += len(scenario_errors)
            
            for error in scenario_errors:
                all_errors.append({
                    "scenario": scenario_name,
                    "text": error["text"],
                    "expected": error["expected"],
                    "predicted": error["predicted"],
                    "method": error["method"],
                    "confidence": error["confidence"],
                    "scores": error["scores"]
                })
        
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ì˜¤ë‹µ: {len(all_errors)}ê°œ (ì˜ˆìƒ: {total_errors}ê°œ)")
        
        if total_errors == 0:
            print("ğŸ‰ ëª¨ë“  ë¬¸ì¥ì´ ì •í™•íˆ ë¶„ë¥˜ë˜ì–´ ì˜¤ë‹µ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            return
        
        # íŒŒì¼ì— ì˜¤ë‹µ ë¬¸ì¥ë“¤ ì €ì¥
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("# MessageClassifier2 ì˜¤ë‹µ ë¬¸ì¥ ë¶„ì„ ê²°ê³¼\n")
                f.write(f"# ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# ì´ ì˜¤ë‹µ ê°œìˆ˜: {total_errors}ê°œ\n")
                f.write("=" * 80 + "\n\n")
                
                # ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥
                current_scenario = ""
                error_count = 1
                
                try:
                    for error in all_errors:
                        # ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘
                        if error["scenario"] != current_scenario:
                            current_scenario = error["scenario"]
                            f.write(f"\n## {current_scenario}\n")
                            f.write("-" * 50 + "\n\n")
                            f.flush()  # ë²„í¼ ê°•ì œ ì“°ê¸°
                        
                        # ì˜¤ë‹µ ì •ë³´ ì €ì¥
                        f.write(f"{error_count}. ë¬¸ì¥: {error['text']}\n")
                        f.write(f"   ì˜ˆìƒ: {error['expected']} â†’ ê²°ê³¼: {error['predicted']}\n")
                        f.write(f"   ë¶„ë¥˜ë°©ë²•: {error['method']}\n")
                        f.write(f"   ì‹ ë¢°ë„: {error['confidence']:.3f}\n")
                        f.write(f"   ì ìˆ˜: {error['scores']}\n")
                        
                        # ë¶„ë¥˜ ì‹¤íŒ¨ íŠ¹ë³„ í‘œì‹œ
                        if error['method'] == 'classification_failed':
                            f.write(f"   âš ï¸  ë¶„ë¥˜ ì‹¤íŒ¨: ëª¨ë“  ë¶„ë¥˜ ë°©ë²•ì´ ì„ê³„ê°’ ë¯¸ë‹¬\n")
                        else:
                            # ì ìˆ˜ ì°¨ì´ ê³„ì‚° (ë¶„ë¥˜ ì‹¤íŒ¨ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
                            try:
                                expected_score = error['scores'][error['expected']]
                                predicted_score = error['scores'][error['predicted']]
                                score_diff = predicted_score - expected_score
                                f.write(f"   ì ìˆ˜ì°¨ì´: {error['predicted']}({predicted_score}) - {error['expected']}({expected_score}) = {score_diff:+d}\n")
                            except KeyError as e:
                                f.write(f"   ì ìˆ˜ì°¨ì´: ê³„ì‚° ì˜¤ë¥˜ - {e}\n")
                        
                        f.write("\n")
                        f.flush()  # ê° ì˜¤ë‹µë§ˆë‹¤ ë²„í¼ ê°•ì œ ì“°ê¸°
                        error_count += 1
                        
                except Exception as write_error:
                    f.write(f"\nâŒ ì˜¤ë‹µ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (#{error_count}): {write_error}\n")
                    f.write(f"ë‚¨ì€ ì˜¤ë‹µ ìˆ˜: {len(all_errors) - error_count + 1}ê°œ\n")
                    f.flush()
                
                # í†µê³„ ì •ë³´ ì¶”ê°€
                f.write("\n" + "=" * 80 + "\n")
                f.write("## ì˜¤ë‹µ í†µê³„ ë¶„ì„\n")
                f.write("=" * 80 + "\n\n")
                
                # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜¤ë‹µ ìˆ˜
                f.write("### ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜¤ë‹µ ê°œìˆ˜:\n")
                for scenario_name, results in self.results["scenarios"].items():
                    error_count = len(results["errors"])
                    total_count = results["total"]
                    error_rate = error_count / total_count * 100 if total_count > 0 else 0
                    f.write(f"- {scenario_name}: {error_count}ê°œ (ì „ì²´ {total_count}ê°œ ì¤‘ {error_rate:.1f}%)\n")
                
                f.write("\n")
                
                # ë¶„ë¥˜ ë°©ë²•ë³„ ì˜¤ë‹µ í†µê³„
                method_errors = {}
                for error in all_errors:
                    method = error["method"]
                    method_errors[method] = method_errors.get(method, 0) + 1
                
                f.write("### ë¶„ë¥˜ ë°©ë²•ë³„ ì˜¤ë‹µ ê°œìˆ˜:\n")
                for method, count in method_errors.items():
                    percentage = count / total_errors * 100
                    f.write(f"- {method}: {count}ê°œ ({percentage:.1f}%)\n")
                
                f.write("\n")
                
                # ì¸ì¬ìƒë³„ ì˜¤ë‹µ í†µê³„  
                trait_errors = {}
                for error in all_errors:
                    expected = error["expected"]
                    predicted = error["predicted"]
                    key = f"{expected} â†’ {predicted}"
                    trait_errors[key] = trait_errors.get(key, 0) + 1
                
                f.write("### ì¸ì¬ìƒë³„ ì˜¤ë‹µ íŒ¨í„´ (ìƒìœ„ 10ê°œ):\n")
                sorted_trait_errors = sorted(trait_errors.items(), key=lambda x: x[1], reverse=True)
                for pattern, count in sorted_trait_errors[:10]:
                    percentage = count / total_errors * 100
                    f.write(f"- {pattern}: {count}ê°œ ({percentage:.1f}%)\n")
            
            print(f"\nğŸ“„ ì˜¤ë‹µ ë¬¸ì¥ ë¶„ì„ ê²°ê³¼ê°€ '{filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"   ì´ {total_errors}ê°œì˜ ì˜¤ë‹µ ë¬¸ì¥ê³¼ ìƒì„¸ ë¶„ì„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print(f"   ì‹¤ì œ ì €ì¥ëœ ì˜¤ë‹µ: {error_count-1}ê°œ")
            
            if error_count-1 != total_errors:
                print(f"âš ï¸  ê²½ê³ : ì˜ˆìƒ ì˜¤ë‹µ ìˆ˜({total_errors})ì™€ ì €ì¥ëœ ì˜¤ë‹µ ìˆ˜({error_count-1})ê°€ ë‹¤ë¦…ë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë‹µ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("MessageClassifier2 ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ê°„ì†Œí™”ëœ ë¶„ë¥˜ê¸°ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤. (5ê°œ ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨)")
    print()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì„ê³„ê°’ 0.1ë¡œ ì„¤ì • - ë” ë¯¼ê°í•˜ê²Œ)
    tester = Classifier2ScenarioTester(similarity_threshold=0.1)
    
    print("í…ŒìŠ¤íŠ¸ ì¶œë ¥ ì˜µì…˜:")
    print("- ìš”ì•½ë§Œ: show_details=False, show_test_sentences=False")
    print("- ìƒ˜í”Œ 5ê°œ: show_details=True, show_test_sentences=False")
    print("- ëª¨ë“  ë¬¸ì¥: show_details=False, show_test_sentences=True")
    print("í˜„ì¬ëŠ” ìš”ì•½ ê²°ê³¼ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n")
    
    # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ë³´ë ¤ë©´: show_test_sentences=Trueë¡œ ë³€ê²½
    tester.run_all_tests(show_details=False, show_test_sentences=True)
    
    print("\n" + "="*80)
    print("âœ¨ MessageClassifier2 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ê°„ì†Œí™”ëœ Sum ë°©ì‹ ë¶„ë¥˜ê¸°ì˜ ì„±ëŠ¥ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. (5ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì „ì²´)")
    print("\nğŸ’¡ ëª¨ë“  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ë³´ë ¤ë©´:")
    print("   tester.run_all_tests(show_test_sentences=True) ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")
    print("\nâš™ï¸  ì„ê³„ê°’ì„ ì¡°ì •í•˜ë ¤ë©´:")
    print("   Classifier2ScenarioTester(similarity_threshold=0.1) ì²˜ëŸ¼ ìƒì„±í•˜ì„¸ìš”.")
    print("   - í•µì‹¬ ê¸°ëŠ¥: ìœ ì§€ (í˜•íƒœì†Œ ë¶„ì„ + Sum ìœ ì‚¬ë„)")
    print("   - ê°„ì†Œí™”: í‚¤ì›Œë“œ ë§¤ì¹­, Word2Vec ë¡œë“œ, ë¬¸ë§¥ íŒ¨í„´")


if __name__ == "__main__":
    main()